import os
import asyncio
from openai import AsyncOpenAI
from dotenv import load_dotenv

# 1. åŠ è½½ .env é‡Œçš„é…ç½®
load_dotenv()

api_key = os.getenv("AI_API_KEY")
base_url = os.getenv("AI_BASE_URL")

print(f"æ­£åœ¨è¿æ¥: {base_url} ...")

async def get_models():
    # 2. åˆå§‹åŒ–å®¢æˆ·ç«¯
    client = AsyncOpenAI(
        api_key=api_key,
        base_url=base_url
    )

    try:
        # 3. å‘é€æ ‡å‡†æŸ¥è¯¢è¯·æ±‚ (GET /v1/models)
        response = await client.models.list()
        
        print("\nâœ… è¿æ¥æˆåŠŸï¼è¯¥å¹³å°æ”¯æŒä»¥ä¸‹æ¨¡å‹ IDï¼š")
        print("=" * 40)
        
        # 4. éå†å¹¶æ‰“å°æ¨¡å‹ ID
        #æœ‰äº›å¹³å°è¿”å›çš„æ•°æ®ç»“æ„æ¯”è¾ƒå¤æ‚ï¼Œæˆ‘ä»¬åšä¸€ä¸ªå…¼å®¹å¤„ç†
        model_list = response.data
        
        # æŒ‰ç…§å­—æ¯é¡ºåºæ’åºï¼Œæ–¹ä¾¿æŸ¥æ‰¾
        sorted_models = sorted(model_list, key=lambda x: x.id)

        for model in sorted_models:
            # é‡ç‚¹æ‰¾åŒ…å« 'deepseek' çš„åå­—
            if "deepseek" in model.id.lower():
                print(f"âœ¨ {model.id}")  # ç»™ä½ é«˜äº®æ˜¾ç¤º DeepSeek ç›¸å…³
            else:
                print(f"   {model.id}")
                
        print("=" * 40)
        print("ğŸ‘‰ è¯·å¤åˆ¶ä¸Šé¢å¸¦ 'âœ¨' çš„å…¶ä¸­ä¸€ä¸ª ID (ä¾‹å¦‚ deepseek-chat æˆ– deepseek-v3)")
        print("ğŸ‘‰ ç„¶åå¡«å…¥ backend/main.py çš„ model='...' é‡Œé¢")

    except Exception as e:
        print(f"\nâŒ æŸ¥è¯¢å¤±è´¥: {e}")
        print("è¯·æ£€æŸ¥ .env æ–‡ä»¶é‡Œçš„ AI_BASE_URL æ˜¯å¦æ­£ç¡® (é€šå¸¸ä¸éœ€è¦åŠ  /chat/completions)")

# è¿è¡Œå¼‚æ­¥ä»»åŠ¡
if __name__ == "__main__":
    asyncio.run(get_models())